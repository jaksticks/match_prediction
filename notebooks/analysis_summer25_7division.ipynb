{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import penaltyblog as pb\n",
    "from types import SimpleNamespace\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from dixon_coles import create_team_ratings, simulate_league, process_simulation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../data/results_kevat25.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures = pd.read_csv('../data/fixtures_kevat25.csv')\n",
    "fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv('../data/table_syksy1_25.csv')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Re-sample results for each team and fit Dixon-Coles. Retain attacking and defensive coefficients.\n",
    "\n",
    "Using sub-sampling without replacement. Removing ratings for teams that end up getting too few matches in the sub-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_samples_per_season = 100\n",
    "nr_season_samples = 10\n",
    "all_samples = []\n",
    "for i in range(nr_season_samples):\n",
    "    sample_array = np.random.choice(results.index, size=nr_samples_per_season, replace=False)\n",
    "    all_samples.append(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dixon-Coles model for each sample of the season\n",
    "\n",
    "min_games_to_include_in_sample = 6\n",
    "all_ratings = []\n",
    "all_sample_results = []\n",
    "args = SimpleNamespace(save_simulation_results=False, league=f'Kevät_2025',)\n",
    "for ix in tqdm(range(len(all_samples)), desc='Fitting models and creating ratings'):\n",
    "    \n",
    "    sample_array = all_samples[ix]\n",
    "    sample_results = results.loc[sample_array]\n",
    "    all_sample_results.append(sample_results)\n",
    "\n",
    "    clf = pb.models.DixonColesGoalModel(\n",
    "        sample_results[\"goals_home\"], \n",
    "        sample_results[\"goals_away\"], \n",
    "        sample_results[\"team_home\"], \n",
    "        sample_results[\"team_away\"],\n",
    "    )\n",
    "    clf.fit()\n",
    "\n",
    "    teams = results['team_home'].unique()    \n",
    "    ratings_df = create_team_ratings(clf, teams, args, export_ratings=False)\n",
    "    \n",
    "    # filter out teams that did not play enough games in the sample\n",
    "    home_counts = sample_results.team_home.value_counts()\n",
    "    away_counts = sample_results.team_away.value_counts()\n",
    "    team_counts = home_counts.add(away_counts, fill_value=0)\n",
    "    team_counts_df = pd.DataFrame(team_counts).reset_index().rename(columns={'index': 'team', 'count': 'games_played'})\n",
    "    ratings_df = pd.merge(ratings_df, team_counts_df, how='left', on='team')\n",
    "    ratings_df = ratings_df[ratings_df.games_played >= min_games_to_include_in_sample]\n",
    "    ratings_df['sample_index'] = ix\n",
    "\n",
    "    all_ratings.append(ratings_df)\n",
    "\n",
    "all_ratings = pd.concat(all_ratings, axis=0).reset_index(drop=True)\n",
    "display(all_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings['color'] = ['red' if team == 'Trikiinit' else 'blue' for team in all_ratings['team']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(all_ratings, x='attack_rating', y='defense_rating', color='color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings.sort_values(by=['attack_rating'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings[all_ratings['team'] == 'Trikiinit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings_grouped = all_ratings.groupby('team').mean()[['attack_rating', 'defense_rating']]\n",
    "all_ratings_grouped['goal_difference_rating'] = all_ratings_grouped['attack_rating'] - all_ratings_grouped['defense_rating']\n",
    "all_ratings_grouped = all_ratings_grouped.sort_values(by='goal_difference_rating', ascending=False)\n",
    "all_ratings_grouped.reset_index(inplace=True)\n",
    "all_ratings_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values\n",
    "attack_values = [value for key, value in clf.get_params().items() if key.startswith('attack')]\n",
    "defence_values = [value for key, value in clf.get_params().items() if key.startswith('defence')]\n",
    "\n",
    "# Create a combined figure manually\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add attack histogram\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=attack_values,\n",
    "    name='Attack',\n",
    "    opacity=0.6,\n",
    "    marker_color='blue'\n",
    "))\n",
    "\n",
    "# Add defence histogram\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=defence_values,\n",
    "    name='Defence',\n",
    "    opacity=0.6,\n",
    "    marker_color='red'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    barmode='overlay',  # or 'group' if you want them side by side\n",
    "    title='Attack vs Defence Parameter Distributions',\n",
    "    xaxis_title='Value',\n",
    "    yaxis_title='Count',\n",
    "    legend_title='Parameter Type'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use ratings from individual groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../output/ratings_Kevät.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "match_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
